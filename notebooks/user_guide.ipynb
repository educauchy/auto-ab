{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use auto_ab library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, yaml, os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(str('../'))\n",
    "from auto_ab import ABTest, Splitter, VarianceReduction, Graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading config file\n",
    "\n",
    "Config file is in *yaml* format and is located in the root of the library.\n",
    "Later in file config is available via *config* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_dir = os.path.dirname(os.path.abspath(''))\n",
    "    config_file = os.path.join(project_dir, 'config.yaml')\n",
    "    with open (config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except yaml.YAMLError as exc:\n",
    "    print(exc)\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')\n",
    "    sys.exit(1)\n",
    "    \n",
    "\n",
    "gf = Graphics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation to the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "\n",
    "- **sex, married, country** — features\n",
    "- **height** — target if target is continuous\n",
    "- **clicks, sessions** — numerator and denominator if target is ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(project_dir, 'data/internal/guide/data.csv'), index_col='id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of splitter\n",
    "\n",
    "If you are going to run MDE simulation, **split_rate** parameter can be omitted as it will be placed to the splitter during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Splitter(split_rate=config['splitter']['split_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of A/B-test\n",
    "\n",
    "Here\n",
    "- **alpha** — significance level\n",
    "- **beta** — probability of type II error\n",
    "- **alternative** — 'less', 'more', 'two-sided'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ABTest(alpha=config['hypothesis']['alpha'], \n",
    "            beta=config['hypothesis']['beta'],\n",
    "            alternative=config['hypothesis']['alternative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set loaded dataset as analyzed\n",
    "\n",
    "Here\n",
    "- **id_col** — id column of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.use_dataset(data, id_col=config['data']['id_col'],\n",
    "              target=config['data']['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set previously defined splitter for test\n",
    "\n",
    "Assign defined splitter to the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.splitter = splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set list of split rates for MDE exploration\n",
    "\n",
    "Set a list of split rates between control/treatment you are going to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.split_rates = config['simulation']['split_rates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set list of increments for MDE exploration\n",
    "\n",
    "Here\n",
    "- **inc_var** — list of increments, i.e. [1, 2, 3, 4, 5]\n",
    "- **extra_paramms** — extra parameters for increment, currently not used in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.set_increment(inc_var=config['simulation']['increment']['vars'],\n",
    "                extra_params=config['simulation']['increment']['extra_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metric which you want to compare\n",
    "\n",
    "In the example below, we want to compare 10th percentile of control and treatment distributions.\n",
    "Metric must return a value over set of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(X: np.array) -> float:\n",
    "    return np.quantile(X, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDE simulation in order to find the best combination of split rate—increment\n",
    "\n",
    "Here\n",
    "- **n_iter** — number of iterations of simulation\n",
    "- **n_boot_samples** — set if you chose bootstrap hypothesis testing\n",
    "- **metric_type** — metric type: ratio or solid (continuous)\n",
    "- **metric** — Python function as tested metric (quantile, median, mean, etc)\n",
    "- **strategy** — strategy of hypothesis testing\n",
    "- **strata** — strata column name for variance reduction\n",
    "- **strata_weights** — weights of each unique value in strata column as a dictionary\n",
    "- **to_csv** — whether or not to save the result to csv file\n",
    "- **csv_path** — path to the newly created csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ab.mde_simulation(n_iter=config['simulation']['n_iter'],\n",
    "                        n_boot_samples=config['simulation']['n_boot_samples'],\n",
    "                       metric_type=config['metric']['metric_type'],\n",
    "                       metric=metric,\n",
    "                       strategy=config['hypothesis']['strategy'],\n",
    "                       strata=config['hypothesis']['strata'],\n",
    "                       strata_weights=config['hypothesis']['strata_weights'],\n",
    "                       to_csv=config['result']['to_csv'],\n",
    "                       csv_path=config['result']['csv_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print simulation log\n",
    "\n",
    "Here\n",
    "- **first key** — split rate\n",
    "- **second key** — increment\n",
    "- **value** — share of rejected H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(res, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize simulation log in plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.plot_simulation_log(config['result']['csv_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual A/B test\n",
    "\n",
    "During this step, dataset of outcomes is gathered and is ready for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/A test\n",
    "\n",
    "Yes, it must be run before A/B test, but let's assume that we have data after A/B test and now we need to assure that splitter is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_data = pd.read_csv(os.path.join(project_dir, 'data/internal/guide/ab_data.csv'))\n",
    "ab_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Splitter(split_rate=0.5)\n",
    "res = splitter.aa_test(X=ab_data, target='height_now', alpha=0.05, n_iter=1000)\n",
    "print(f'Share of iterations when control and treatment groups are equal: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset generated during A/B-test\n",
    "\n",
    "Here\n",
    "- **height_now** — experiment metric during experiment\n",
    "- **height_prev** — experiment metric before experiment\n",
    "- **weight_now** — highly correlated feature with metric during experiment\n",
    "- **weight_prev** — highly correlated feature with metric before experiment\n",
    "- **noise_now** — feature during experiment that is just noise\n",
    "- **noise_prev** — feature before experiment that is just noise\n",
    "- **groups** — groups column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_data = pd.read_csv(os.path.join(project_dir, 'data/internal/guide/ab_data.csv'))\n",
    "ab_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial distribution of tested metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.plot_distributions(ab_data, 'height_now', 'groups', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, distributions are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add increment to the treatment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ABTest(alpha=config['hypothesis']['alpha'], \n",
    "            beta=config['hypothesis']['beta'],\n",
    "            alternative=config['hypothesis']['alternative'])\n",
    "\n",
    "treatment = ab_data.loc[ab_data.groups == 'B', 'height_now']\n",
    "treatment_increased = ab._add_increment('solid', treatment, 5)\n",
    "ab_data.loc[ab_data.groups == 'B', 'height_now'] = treatment_increased\n",
    "\n",
    "gf.plot_distribution(treatment_increased, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial control and increased treatment distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.plot_distributions(ab_data, 'height_now', 'groups', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use CUPED to reduce variance\n",
    "\n",
    "After the execution, new column is introduced — **height_now_cuped**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = VarianceReduction()\n",
    "ab_data_cuped = vr.cuped(ab_data, target='height_now', groups='groups', covariate='height_prev')\n",
    "print(ab_data_cuped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.plot_distributions(ab_data_cuped, 'height_now_cuped', 'groups', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, variance reduced **from 160 to 170** and **from 190 to 180** for control and **from 165 to 175** and **from 195 to 185** for treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use CUPAC to reduce variance\n",
    "\n",
    "Below you can see the model that was created to predict covariate to experiment period.\n",
    "After the execution, new column is introduced — **target_pred**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_data_cupac = vr.cupac(ab_data, target_prev='height_prev', target_now='height_now',\n",
    "               factors_prev=['weight_prev'],\n",
    "               factors_now=['weight_now'], groups='groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ab_data_cupac.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.plot_distributions(ab_data_cupac, 'height_now_cuped', 'groups', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, variance reduced **from 160 to 170** on the left and **from 190 to 180** on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B-test analysis\n",
    "\n",
    "Metric tested in the experiment in 10th quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(X: np.array) -> float:\n",
    "    return np.quantile(X, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ABTest(alpha=config['hypothesis']['alpha'],\n",
    "            beta=config['hypothesis']['beta'],\n",
    "            alternative=config['hypothesis']['alternative'])\n",
    "\n",
    "control = ab_data_cuped.loc[ab_data_cuped.groups == 'A', 'height_now_cuped'].to_numpy()\n",
    "treatment = ab_data_cuped.loc[ab_data_cuped.groups == 'B', 'height_now_cuped'].to_numpy()\n",
    "\n",
    "is_rejected = ab.test_hypothesis_buckets(control, treatment, metric, 100)\n",
    "result = 'rejected' if is_rejected == 1 else 'not rejected'\n",
    "print(f'H0: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
