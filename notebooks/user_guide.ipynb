{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use auto_ab library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, yaml, os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(str('../'))\n",
    "from auto_ab import ABTest, Splitter, VarianceReduction, Graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_dir = os.path.dirname(os.path.abspath(''))\n",
    "    config_file = os.path.join(project_dir, 'config.yaml')\n",
    "    with open (config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except yaml.YAMLError as exc:\n",
    "    print(exc)\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(project_dir, 'data/data.csv'), index_col='id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of splitter\n",
    "\n",
    "If you are going to run MDE simulation, **split_rate** parameter can be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Splitter(split_rate=config['splitter']['split_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of A/B-test\n",
    "\n",
    "Here\n",
    "- **alpha** — significance level\n",
    "- **alternative** — 'less', 'more', 'two-sided'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ABTest(alpha=config['hypothesis']['alpha'], \n",
    "            alternative=config['hypothesis']['alternative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set loaded dataset as analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.use_dataset(data, id_col=config['data']['id_col'],\n",
    "              target=config['data']['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set previously defined splitter for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.splitter = splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set list of split rates for MDE exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.split_rates = config['simulation']['split_rates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set list of increments for MDE exploration\n",
    "\n",
    "Here\n",
    "- **inc_var** — list of increments, i.e. [1, 2, 3, 4, 5]\n",
    "- **extra_paramms** — extra parameters for increment, currently not used in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.set_increment(inc_var=config['simulation']['increment']['vars'],\n",
    "                extra_params=config['simulation']['increment']['extra_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metric which you want to compare\n",
    "\n",
    "In the example below, we want to compare 10th percentile of control and treatment distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(X: np.array) -> float:\n",
    "    return np.quantile(X, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDE simulation in order to find the best combination of split rate—increment\n",
    "\n",
    "Here\n",
    "- **n_iter** — number of iterations of simulation\n",
    "- **n_boot_samples** — set if you choose bootstrap hypothesis testing\n",
    "- **metric_type** — metric type: ratio or solid (continuous)\n",
    "- **metric** — Python function as tested metric (quantile, median, mean, etc)\n",
    "- **strategy** — strategy of hypothesis testing\n",
    "- **strata** — strata column name for variance reduction\n",
    "- **strata_weights** — weights of each unique value in strata column as a dictionary\n",
    "- **to_csv** — whether or not to save the result to csv file\n",
    "- **csv_path** — path to the newly created csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ab.mde_simulation(n_iter=config['simulation']['n_iter'],\n",
    "                       n_boot_samples=config['hypothesis']['n_boot_samples'],\n",
    "                       metric_type=config['metric']['metric_type'],\n",
    "                       metric=metric,\n",
    "                       strategy=config['hypothesis']['strategy'],\n",
    "                       strata=config['hypothesis']['strata'],\n",
    "                       strata_weights=config['hypothesis']['strata_weights'],\n",
    "                       to_csv=config['result']['to_csv'],\n",
    "                       csv_path=config['result']['csv_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print simulation log\n",
    "\n",
    "Here\n",
    "- **first key** — split rate\n",
    "- **second key** — increment\n",
    "- **value** — share of rejected H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(res, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize simulation log in plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = Graphics()\n",
    "gf.plot_simulation_log(config['result']['csv_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
